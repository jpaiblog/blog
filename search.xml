<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Face API 顔認識機能をプログラミングせずに利用する方法</title>
      <link href="/blog/2020/10/19/face-identify-without-coding/"/>
      <url>/blog/2020/10/19/face-identify-without-coding/</url>
      
        <content type="html"><![CDATA[<p>Face API 顔認識機能を、プログラミングせずに利用する方法をご紹介します。</p><ul><li><a href="#利用にあたり推奨するサンプル画像について">利用にあたり推奨するサンプル画像</a></li><li><a href="#手順概要">手順概要</a></li><li><a href="#手順詳細">手順詳細</a><a id="more"></a></li><li><a href="#(準備)キーとエンドポイントを確認">(準備)キーとエンドポイントを確認</a> </li><li><a href="#Ⅰ-1.グループを登録する">Ⅰ-1.グループを登録する</a></li><li><a href="#Ⅰ-2.グループに対して、人物を登録する">Ⅰ-2.グループに対して、人物を登録する</a></li><li><a href="#Ⅰ-3.学習用画像の準備">Ⅰ-3.学習用画像の準備 </a></li><li><a href="#Ⅰ-4.人物に対して、学習用画像を登録する">Ⅰ-4.人物に対して、学習用画像を登録する</a></li><li><a href="#Ⅰ-5.モデルの学習">Ⅰ-5.モデルの学習</a></li><li><a href="#Ⅰ-6.学習結果の確認">Ⅰ-6.学習結果の確認</a></li><li><a href="#Ⅱ-1.顔認識用画像の準備">Ⅱ-1.顔認識用画像の準備</a></li><li><a href="#Ⅱ-2.顔認識の実行">Ⅱ-2.顔認識の実行</a><br></li></ul><hr><h1 id="利用にあたり推奨するサンプル画像について"><a href="#利用にあたり推奨するサンプル画像について" class="headerlink" title="利用にあたり推奨するサンプル画像について"></a>利用にあたり推奨するサンプル画像について</h1><p>利用にあたっては、<a href="https://github.com/MicrosoftDocs/ai-fundamentals/blob/master/01d%20-%20Face%20Analysis.ipynb" target="_blank" rel="noopener">チュートリアル</a>で利用されているサンプル画像の利用を推奨します。<br/><br>顔認識には<a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/face/concepts/face-recognition#input-data" target="_blank" rel="noopener">一定以上の品質の画像</a>が必要となるため、まずは以下のサンプル画像でお試しをいただければスムーズに確認が進みます。</p><h4 id="ai-fundamentals-data-face-wendell-（学習する人物画像として利用）"><a href="#ai-fundamentals-data-face-wendell-（学習する人物画像として利用）" class="headerlink" title="ai-fundamentals/data/face/wendell　（学習する人物画像として利用）"></a>ai-fundamentals/data/face/wendell　（学習する人物画像として利用）</h4><ul><li><a href="https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/wendell/Wendell_01.jpg" target="_blank" rel="noopener">https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/wendell/Wendell_01.jpg</a></li><li><a href="https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/wendell/Wendell_02.jpg" target="_blank" rel="noopener">https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/wendell/Wendell_02.jpg</a></li><li><a href="https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/wendell/Wendell_03.jpg" target="_blank" rel="noopener">https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/wendell/Wendell_03.jpg</a><br/><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face01.jpg" alt="face01" title="face01">  </li></ul><h4 id="ai-fundamentals-data-face-employees-jpg-（顔認識対象の画像として利用）"><a href="#ai-fundamentals-data-face-employees-jpg-（顔認識対象の画像として利用）" class="headerlink" title="ai-fundamentals/data/face/employees.jpg　（顔認識対象の画像として利用）"></a>ai-fundamentals/data/face/employees.jpg　（顔認識対象の画像として利用）</h4><ul><li><a href="https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/employees.jpg" target="_blank" rel="noopener">https://raw.githubusercontent.com/MicrosoftDocs/ai-fundamentals/master/data/face/employees.jpg</a><br/></li></ul><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face02.jpg" alt="face02" title="face02"> </p><hr><h1 id="手順概要"><a href="#手順概要" class="headerlink" title="手順概要"></a>手順概要</h1><p>手順の概要は、以下の表のとおりです。<br /><br /><br>Ⅰ-1 から、Ⅱ-2に至るまで、順に、[API] 列のリンクをクリックして開く リファレンスAPIページ（一部について製品デモページ）での処理実行をお試しください。<br/><br>なお、「Ⅰ-4 学習用画像の登録」（および「Ⅰ-3 学習用画像の準備」）については一括登録が行えないため、学習画像の枚数分、複数回の実行が必要です。<br /><br><br /></p><h3 id="Ⅰ-モデルの学習を行う"><a href="#Ⅰ-モデルの学習を行う" class="headerlink" title="Ⅰ.モデルの学習を行う"></a>Ⅰ.モデルの学習を行う</h3><table><thead><tr><th>手順内容</th><th>API</th><th>主要な送信パラメータ</th><th>主要な受信パラメータ</th><th>備考</th></tr></thead><tbody><tr><td>1.グループを登録する</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395244" target="_blank" rel="noopener">PersonGroup - Create</a></td><td>グループID, グループ名</td><td>-</td><td>グループIDはユーザーが任意に設定する</td></tr><tr><td>2.グループに対して、人物を登録する</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523c" target="_blank" rel="noopener">PersonGroup Person – Create</a></td><td>グループID, 人物名</td><td>人物ID</td><td>人物IDは自動で設定される</td></tr><tr><td>3.学習用画像の準備</td><td><a href="https://azure.microsoft.com/ja-jp/services/cognitive-services/face/#demo" target="_blank" rel="noopener">Face - Detect</a></td><td>人物画像のURL</td><td>顔ID, 画像のURLから顔として認識された領域の座標情報</td><td>検出した顔座標が画像上に可視化される利便があるため、デモ画面の利用を推奨</td></tr><tr><td>4.人物に対して、学習用画像を登録する</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523b" target="_blank" rel="noopener">PersonGroup Person - Add Face</a></td><td>グループID, 人物ID, 人物画像のURL, 人物画像の中の顔領域の座標情報</td><td>-</td><td>学習用画像の登録は画像1枚ずつの登録。REST APIでは一括登録不可</td></tr><tr><td>5.モデルの学習</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249" target="_blank" rel="noopener">PersonGroup - Train</a></td><td>グループID</td><td>-</td><td>-</td></tr><tr><td>6.学習結果の確認</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395247" target="_blank" rel="noopener">PersonGroup - Get Training Status</a></td><td>グループID</td><td>学習結果状況</td><td>-</td></tr></tbody></table><p>　</p><h3 id="Ⅱ-顔認識を行う"><a href="#Ⅱ-顔認識を行う" class="headerlink" title="Ⅱ.顔認識を行う"></a>Ⅱ.顔認識を行う</h3><table><thead><tr><th>手順内容</th><th>API</th><th>主要な送信パラメータ</th><th>主要な受信パラメータ</th><th>備考</th></tr></thead><tbody><tr><td>1.顔認識用画像の準備</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236" target="_blank" rel="noopener">Face - Detect</a></td><td>人物画像のURL</td><td>顔ID, 画像のURLから顔として認識された領域の座標情報</td><td>自分のキー配下で発行される顔IDを取得するために、リファレンスAPIページを利用<br/><br/>（任意）デモ画面で検出した顔座標状況を確認</td></tr><tr><td>2.顔認識の実行</td><td><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239" target="_blank" rel="noopener">Face - Identify</a></td><td>グループID, 顔ID</td><td>(顔IDごとに) 人物ID, 確度</td><td>-</td></tr></tbody></table><hr><h1 id="手順詳細"><a href="#手順詳細" class="headerlink" title="手順詳細"></a>手順詳細</h1><p>以下にご参考まで、2020年10月時点の各手順実行時のスクリーンショットを貼付します。</p><hr><h1 id="準備-キーとエンドポイントを確認"><a href="#準備-キーとエンドポイントを確認" class="headerlink" title="(準備)キーとエンドポイントを確認"></a>(準備)キーとエンドポイントを確認</h1><p>Azure ポータル画面のFaceリソース画面で、キーとエンドポイントを確認します。キーは後続の処理で利用するので、その文字列を取り置きます。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face03.jpg" alt="face03" title="face03"> </p><hr><h1 id="Ⅰ-1-グループを登録する"><a href="#Ⅰ-1-グループを登録する" class="headerlink" title="Ⅰ-1.グループを登録する"></a>Ⅰ-1.グループを登録する</h1><p>(1) <a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395244" target="_blank" rel="noopener">リファレンスAPI</a>ページにアクセスすると、ページの中ほどにエンドポイントを選択するセクションがあります。<br>前の手順で確認したエンドポイントが記載された青いボックスをクリックして、テスト用ページへ遷移します。<br /></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face04.jpg" alt="face04" title="face04"></p><p>(2) テスト用ページの中ほどに、パラメータを設定するセクションがあります。<br /><br>Ocp-Apim-Subscription-Key　には、前の手順で確認したキー情報を設定します。<br /><br>その他項目は、以下の画像のように設定します。<br />グループID (personGroupId) もグループ名称 (name) も、ユーザーで任意に設定可能です。<br>また、Request body に設定する userData はオプション項目のため、削除せずに付加したままでも構いません。<br /><br>パラメータを設定し終わったら、[Send] ボタンをクリックします。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face05.jpg" alt="face05" title="face05"></p><p>(3) レスポンスセクションに結果が表示されます。 以下の画像のように [200 OK] と応答があれば問題ありません。処理が成功しています。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face06.jpg" alt="face06" title="face06"></p><hr><h1 id="Ⅰ-2-グループに対して、人物を登録する"><a href="#Ⅰ-2-グループに対して、人物を登録する" class="headerlink" title="Ⅰ-2.グループに対して、人物を登録する"></a>Ⅰ-2.グループに対して、人物を登録する</h1><p>（以降、前の手順と重複するエンドポイント選択手順などは割愛します。<br /><br>　ご参考として、リクエストセクションと、レスポンスセクションのスクリーンショットをそれぞれ貼付します）<br /><br><br /><br><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523c" target="_blank" rel="noopener">PersonGroup Person – Create</a> ページを開きます。<br /><br /><br>(1) リクエストセクション<br /><br>前の手順で設定したグループIDを入力します。<br/><br>人物名は、ユーザー様で任意に設定可能です（この名称は以降の手順では特に利用しません）<br/></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face07.jpg" alt="face07" title="face07"></p><p>(2) レスポンスセクション<br /><br>以降の手順で必要となるため、自動で設定された personId を取り置きます。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face08.jpg" alt="face08" title="face08"></p><hr><h1 id="Ⅰ-3-学習用画像の準備"><a href="#Ⅰ-3-学習用画像の準備" class="headerlink" title="Ⅰ-3.学習用画像の準備"></a>Ⅰ-3.学習用画像の準備</h1><p><a href="https://azure.microsoft.com/ja-jp/services/cognitive-services/face/#demo" target="_blank" rel="noopener">デモ画面</a>を開き、[Face Detection] デモが選択されていることを確認します。<br /><br>以下の画像のように、画面左下の [画像のURL] 入力項目にURLを入力して [送信]　ボタンをクリックします。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face09.jpg" alt="face09" title="face09"></p><p>画面右側に、顔として認識された領域の座標情報が出力されます。<br /><br>同時に画面左側に、その領域が元の顔画像に青いバウンディングボックスとして可視化されるので、どこが顔として認識されたのかが容易に確認可能です。</p><p>次の手順のために、画面右側に出力された座標情報を取り置きます。</p><hr><h1 id="Ⅰ-4-人物に対して、学習用画像を登録する"><a href="#Ⅰ-4-人物に対して、学習用画像を登録する" class="headerlink" title="Ⅰ-4.人物に対して、学習用画像を登録する"></a>Ⅰ-4.人物に対して、学習用画像を登録する</h1><p><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523b" target="_blank" rel="noopener">PersonGroup Person - Add Face</a> ページを開きます。<br /></p><p>(1) リクエストセクション<br /><br>これまでの手順で設定および取得した、グループIDと人物IDを入力します。<br/><br>また、targetFace には、前の手順で取得した顔として認識された領域の座標情報を入力します。以下のようなフォーマット変換が必要です。<br/></p><table><thead><tr><th>フォーマット変換前</th><th>フォーマット（”targetFace=left,top,width,height”）変換後</th></tr></thead><tbody><tr><td>“faceRectangle”: {“top”: 313,”left”: 205,”width”: 459,”height”: 626},</td><td>205,313,459,626</td></tr><tr><td><br />detectionModelは、現時点で最新の detection_02 バージョンを選択します。<br /></td><td></td></tr><tr><td>urlには、前の手順と同じ画像のURLを入力します。<br /></td><td></td></tr></tbody></table><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face10.jpg" alt="face10" title="face10"></p><p>(2) レスポンスセクション<br /><br>[200 OK] と応答があれば問題ありません。また、ここで返却される persistedFaceId は以降の手順で利用しません。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face11.jpg" alt="face11" title="face11"></p><hr><h1 id="Ⅰ-5-モデルの学習"><a href="#Ⅰ-5-モデルの学習" class="headerlink" title="Ⅰ-5.モデルの学習"></a>Ⅰ-5.モデルの学習</h1><p><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249" target="_blank" rel="noopener">PersonGroup - Train</a> ページを開きます。<br /><br /><br>(1) リクエストセクション<br /><br>グループIDを設定します。<br /></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face12.jpg" alt="face12" title="face12"></p><p>(2) レスポンスセクション<br /><br>[202 Accepted]の応答があれば問題ありません。次の手順で、学習の結果を確認します。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face13.jpg" alt="face13" title="face13"></p><hr><h1 id="Ⅰ-6-学習結果の確認"><a href="#Ⅰ-6-学習結果の確認" class="headerlink" title="Ⅰ-6.学習結果の確認"></a>Ⅰ-6.学習結果の確認</h1><p><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395247" target="_blank" rel="noopener">PersonGroup - Get Training Status</a> ページを開きます。<br /><br /><br>(1) リクエストセクション<br /><br>グループIDを設定します。<br /></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face14.jpg" alt="face14" title="face14"></p><p>(2) レスポンスセクション<br /><br>“status”: “succeeded” と返却されていれば問題ありません。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face15.jpg" alt="face15" title="face15"></p><hr><h1 id="Ⅱ-1-顔認識用画像の準備"><a href="#Ⅱ-1-顔認識用画像の準備" class="headerlink" title="Ⅱ-1.顔認識用画像の準備"></a>Ⅱ-1.顔認識用画像の準備</h1><p><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236" target="_blank" rel="noopener">Face - Detect</a> ページを開きます。<br /><br /><br>(1) リクエストセクション<br /><br>recognitionModelで、現時点で最新の recognition_03 バージョンを選択します。<br /><br>detectionModelで、現時点で最新の detection_02 バージョンを選択します。<br /><br>urlに顔認識用画像のURLを入力します。<br><br /></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face16.jpg" alt="face16" title="face16"></p><p>(2) レスポンスセクション<br /><br>次の手順のために、出力されたfaceIdを取り置きます。<br /><br><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face17.jpg" alt="face17" title="face17"></p><br />※ 任意手順<br /><p><a href="https://azure.microsoft.com/ja-jp/services/cognitive-services/face/#demo" target="_blank" rel="noopener">デモ画面</a> で、以下のように顔認識用画像のURLを入力して [送信]　し、検出された顔座標の状況を目視確認します。<br /><br>サンプル画像に detection_02 モデルを適用すると、2つの顔が検出されます。<br/></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face18.jpg" alt="face18" title="face18"></p><hr><h1 id="Ⅱ-2-顔認識の実行"><a href="#Ⅱ-2-顔認識の実行" class="headerlink" title="Ⅱ-2.顔認識の実行"></a>Ⅱ-2.顔認識の実行</h1><p><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239" target="_blank" rel="noopener">Face - Identify</a> ページを開きます。<br /><br /><br>(1) リクエストセクション<br /><br>Request bodyに、以下のように設定します。<br /><br>largePersonGroupId <strong>を削除し</strong>、<strong>personGroupId</strong>　にキーを変更します。そして、グループIDを入力します。<br /><br>faceIds には、以下のように前の手順で取得した顔IDを入力します。<br/></p><blockquote><p>{<br>   “<strong>personGroupId</strong>“: “groupid01”,<br/><br>   “<strong>faceIds</strong>“: [<br/><br>   “17d2e2a6-c891-4f16-bf6e-14180c9b0e8b”,<br/><br>    “a3a2ce7c-3743-4819-ae8f-47d4940bbee5”<br/><br>   ],<br/><br>   “maxNumOfCandidatesReturned”: 1,<br/><br>   “confidenceThreshold”: 0.5<br/><br>}</p></blockquote><p>maxNumOfCandidatesReturned などの項目は、既定のままでも、画面に表示されている説明に準じて、値を変更いただいても問題ありません。</p><p>(2) レスポンスセクション<br /><br>顔IDごとに、顔認識の結果として、その人物IDと確度（0から1の値をとります）が返却されます。<br /><br>人物IDが返却されない場合は、パラメータセクションで confidenceThreshold に設定した以上の値の確度で認識した人物に該当がなかったことを示します。<br><br /><br>以下の画像が示す結果は、検出された2つの顔のうち、1つの顔には該当する登録済人物がおらず、もう1つの顔については 0.94 の確度で登録済の人物が該当するという内容になります。<br /></p><p><img src="https://jpaiblog.github.io/images/face-identify-without-coding/face19.jpg" alt="face19" title="face19"></p><hr><p><code>変更履歴</code><br><code>2020/10/19 created by Uehara</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Face API </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Face API Recognition Identify </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LUIS オーサリング リソースへの移行について</title>
      <link href="/blog/2020/06/05/LUIS-authoring-resource/"/>
      <url>/blog/2020/06/05/LUIS-authoring-resource/</url>
      
        <content type="html"><![CDATA[<p>LUIS オーサリング リソースへの移行について、オーサリング リソースの役割および移行による変更点を紹介します。</p><a id="more"></a><br><hr><p>現在 LUIS では Azure オーサリング リソースへの移行を進めており、<a href="https://www.luis.ai" target="_blank" rel="noopener">LUIS ポータル</a> 上での通知に加えて、対象ユーザーには個別で移行に関するご案内をしています。この記事では LUIS オーサリング リソースがどのような役割を持っているのか、また、移行を行うことによる変更点を紹介します。</p><h3 id="■LUIS-オーサリング-リソースの役割"><a href="#■LUIS-オーサリング-リソースの役割" class="headerlink" title="■LUIS オーサリング リソースの役割"></a>■LUIS オーサリング リソースの役割</h3><p>これまで LUIS は、利用開始に Azure サブスクリプションを必要としないサービスとして提供されてきました。Azure サブスクリプションをお持ちでなくても、LUIS のアプリケーションを作成することはできますが、実際にアプリケーションを Bot などから利用する場合には、 Azure の LUIS ランタイム (Prediciton) リソースをアプリケーションに紐づけて使用しています。</p><p>この場合、LUIS のアプリケーションは LUIS ポータルにサインインした、各ユーザーのアカウント (メールアドレス) に関連付けられています。一方で、ユーザーのメールアドレスに紐づけて管理していることにより、以下のような問題がありました。</p><ul><li>LUIS アプリケーションの所有権を他のユーザーに移転できない</li><li>Azure とは独立したシステムでアクセス権を制御するため統一的な管理が困難</li></ul><p>これらの問題を解決するため、LUIS のアプリケーション管理を Azure に統合する方針となり、LUIS オーサリング リソースが導入されました。</p><p>オーサリング リソースを使用しない場合と、オーサリング リソースを使用した場合の、アプリケーションの関連付けや共有方法の違いを図にまとめると以下のようになります。</p><p><img src="https://jpaiblog.github.io/images/LUIS-authoring-resource/LUIS-migration.png" alt="LUIS-migration"></p><p>他のユーザーが所有するアプリケーションにアクセスするには、移行前はコラボレーターと呼ばれる機能により、メールアドレス ベースで、アプリごとに設定する必要がありました。</p><p>一方で移行すると、 LUIS アプリケーションは LUIS オーサリング リソースに関連付けられ、そのリソースに対するアクセス権を Azure の標準的なロールベースのアクセス制御 (RBAC) で管理できるようになります。</p><h3 id="■ランタイム-リソースとオーサリング-リソースの関係"><a href="#■ランタイム-リソースとオーサリング-リソースの関係" class="headerlink" title="■ランタイム リソースとオーサリング リソースの関係"></a>■ランタイム リソースとオーサリング リソースの関係</h3><p>オーサリング リソースは LUIS アプリケーションを作成・編集するためだけに使用されます。予測エンドポイント API の使用には、引き続き LUIS アプリケーションに関連付けた、ランタイム (Prediciton) リソース、もしくは試用版の API キー (スターター キー) が必要です。この 2 種類のリソースの違いを図にすると以下のようになります。</p><p><img src="https://jpaiblog.github.io/images/LUIS-authoring-resource/LUIS-auth-endpoint-diff.png" alt="LUIS-auth-endpoint-diff"></p><p>ここで、オーサリング リソースを作成するリージョンと、ランタイム リソースを作成するリージョンは、顧客データの取り扱いに特別なルールがある地域 (オーストラリア、ヨーロッパ) を除き、異なるリージョンになっていても構いません。</p><p>2020 年 6 月 5 日現在、上記 2 つの地域以外のリージョンで LUIS アプリケーションを公開する場合は、オーサリング リソースのリージョンは米国西部のみとなります。公開を行うと、アプリケーションに関連付けられたランタイム リソースのリージョン (図の例では東日本リージョン) に自動で展開されます。</p><h3 id="■関連する公開ドキュメント"><a href="#■関連する公開ドキュメント" class="headerlink" title="■関連する公開ドキュメント"></a>■関連する公開ドキュメント</h3><ul><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/luis/luis-migration-authoring" target="_blank" rel="noopener">Azure リソース オーサリング キーに移行する</a></li><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/luis/luis-migration-authoring-steps" target="_blank" rel="noopener">Azure オーサリング リソースに移行するための手順</a></li><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/luis/luis-concept-keys" target="_blank" rel="noopener">オーサリング キーとランタイム キー</a></li><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/luis/luis-reference-regions#publishing-regions" target="_blank" rel="noopener">作成と公開のリージョンと関連付けられているキー</a></li></ul><h3 id="■FAQ"><a href="#■FAQ" class="headerlink" title="■FAQ"></a>■FAQ</h3><h4 id="Q-オーサリング-リソースに移行しないとどうなる？"><a href="#Q-オーサリング-リソースに移行しないとどうなる？" class="headerlink" title="Q. オーサリング リソースに移行しないとどうなる？"></a>Q. オーサリング リソースに移行しないとどうなる？</h4><p>A. 2020 年 6 月 5 日現在、オーサリング リソースの移行期限は 2020 年 9 月 30 日となっております。2020 年 10 月 1 日時点で移行されていないアプリケーションはアクセスできなくなる可能性があります。</p><h4 id="Q-オーサリングリソースの移行単位は？"><a href="#Q-オーサリングリソースの移行単位は？" class="headerlink" title="Q. オーサリングリソースの移行単位は？"></a>Q. オーサリングリソースの移行単位は？</h4><p>A. オーサリング リソースへの移行は、 LUIS ポータルにサインインするユーザーアカウント単位です。移行作業では、自身が所有している LUIS アプリケーションを、どのオーサリング リソースに関連付けるかを指定します。組織単位でまとめて実施するような方法はありません。</p><h4 id="Q-オーサリング-リソースへの移行でダウンタイムが発生する？"><a href="#Q-オーサリング-リソースへの移行でダウンタイムが発生する？" class="headerlink" title="Q. オーサリング リソースへの移行でダウンタイムが発生する？"></a>Q. オーサリング リソースへの移行でダウンタイムが発生する？</h4><p>A. オーサリング リソースに移行しても、LUIS アプリケーションとランタイム リソースの紐づけはそのまま維持されます。移行作業中もエンドポイント API の呼び出しについてダウンタイムは通常発生しません。</p><h4 id="Q-オーサリング-リソースに移行したら他のユーザーからアプリケーションが見えなくなった"><a href="#Q-オーサリング-リソースに移行したら他のユーザーからアプリケーションが見えなくなった" class="headerlink" title="Q. オーサリング リソースに移行したら他のユーザーからアプリケーションが見えなくなった"></a>Q. オーサリング リソースに移行したら他のユーザーからアプリケーションが見えなくなった</h4><p>A. 移行前のコラボレーターの設定は自動では移行されませんので、移行後に RBAC で適切な権限の再設定が必要です。また RBAC の設定が適切でも、移行していないユーザーは、移行後のアプリケーションを LUIS ポータルで確認することはできません。</p><h4 id="Q-LUIS-の新規ユーザーはどうなる？"><a href="#Q-LUIS-の新規ユーザーはどうなる？" class="headerlink" title="Q. LUIS の新規ユーザーはどうなる？"></a>Q. LUIS の新規ユーザーはどうなる？</h4><p>A. 2020 年 6 月 5 日現在は LUIS の使用開始時に、アプリケーションの紐づけ先となる LUIS オーサリング リソースを指定するか、オーサリング リソースを利用せず試用版 (スターター キー) を使用するか選択できます。ここでオーサリング リソースを選択しなかった場合は期限までに移行が必要です。</p><h4 id="Q-LUIS-のアプリケーション単位で他のユーザーと共有したい"><a href="#Q-LUIS-のアプリケーション単位で他のユーザーと共有したい" class="headerlink" title="Q. LUIS のアプリケーション単位で他のユーザーと共有したい"></a>Q. LUIS のアプリケーション単位で他のユーザーと共有したい</h4><p>A. 移行後はオーサリング リソースにアプリケーションが関連付けられます。アクセス権を付与できるのはオーサリング リソース単位で、アプリケーション単位では付与できません。新しいオーサリング リソースを作成して、共有したいアプリケーションのみをインポートすることで、特定のアプリケーションを共有できます。</p><hr><p><code>変更履歴</code><br><code>2020/06/05 created by Nakagami</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Cognitive Services </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LUIS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Translator Text API の翻訳文字数の確認方法</title>
      <link href="/blog/2020/05/28/TranslatorTextAPI-char-translated/"/>
      <url>/blog/2020/05/28/TranslatorTextAPI-char-translated/</url>
      
        <content type="html"><![CDATA[<p>Translator Text API の翻訳文字数の確認方法と、参考情報をご紹介します。</p><ol><li><a href="#翻訳文字数データの確認手順">翻訳文字数データの確認手順</a></li><li><a href="#翻訳文字数データをファイルとしてダウンロードする手順">翻訳文字数データをファイルとしてダウンロードする手順</a></li><li><a href="#（参考情報）文字数カウント方法に関する公開ドキュメント">（参考情報）文字数カウント方法に関する公開ドキュメント</a> <a id="more"></a><br></li></ol><hr><h1 id="翻訳文字数データの確認手順"><a href="#翻訳文字数データの確認手順" class="headerlink" title="翻訳文字数データの確認手順"></a>翻訳文字数データの確認手順</h1><p>(1) Azure Portal 上で、対象のTranslator Text API のリソースを選択します。<br>(2) [監視] ブレードの [メトリック] をクリックします。<br>(3) 表示された、画面中央の [メトリック] から [Characters Translated] を選択します。<br><img src="https://jpaiblog.github.io/images/TranslatorTextAPI-char-translated/char1-3.jpg" alt="char-translated-1-3" title="char-translated-1-3">  </p><p>(4) 画面右上にある [現地時刻: 過去 24 時間 (自動)] をクリックし、表示されたポップアップから希望の時間範囲と粒度を設定します。<br><img src="https://jpaiblog.github.io/images/TranslatorTextAPI-char-translated/char1-4.jpg" alt="char-translated-1-4" title="char-translated-1-4">  </p><p>(5) グラフ上に指定した期間の翻訳文字数が表示されます。<br><img src="https://jpaiblog.github.io/images/TranslatorTextAPI-char-translated/char1-5.jpg" alt="char-translated-1-5" title="char-translated-1-5">  </p><p>(6) グラフの中で確認したい時点にカーソルをあてると、その時間帯（指定した時間の粒度単位）に絞って、翻訳文字数を表示することができます。<br><img src="https://jpaiblog.github.io/images/TranslatorTextAPI-char-translated/char1-6.jpg" alt="char-translated-1-6" title="char-translated-1-6">  </p><p>翻訳文字数のグラフを表示する際に設定したメトリック [Characters Translated] の説明は、下記の公開ドキュメントを参照ください。  </p><ul><li><a href="https://docs.microsoft.com/en-us/azure/azure-monitor/platform/metrics-supported#microsoftcognitiveservicesaccounts" target="_blank" rel="noopener">Supported metrics with Azure Monitor #Microsoft.CognitiveServices/accounts</a><blockquote><p>Characters Translated</p><blockquote><p>Total number of characters in incoming text request.</p></blockquote></blockquote></li></ul><hr><h1 id="翻訳文字数データをファイルとしてダウンロードする手順"><a href="#翻訳文字数データをファイルとしてダウンロードする手順" class="headerlink" title="翻訳文字数データをファイルとしてダウンロードする手順"></a>翻訳文字数データをファイルとしてダウンロードする手順</h1><p>(1) “１．翻訳文字数データの確認手順” に沿って、翻訳文字数のグラフを表示します。<br>(2) 表示された翻訳文字数のグラフ上部の　[共有] プルダウンから [Excelへのダウンロード] を選択します。<br><img src="https://jpaiblog.github.io/images/TranslatorTextAPI-char-translated/char2-2.jpg" alt="char-translated-2-2" title="char-translated-2-2">  </p><p>(3) 翻訳文字数のグラフを表示する際に設定した “メトリック”, “時間の範囲および粒度” のデータのExcelファイルがダウンロードされます。<br><img src="https://jpaiblog.github.io/images/TranslatorTextAPI-char-translated/char2-3.jpg" alt="char-translated-2-3" title="char-translated-2-3">  </p><hr><h1 id="（参考情報）文字数カウント方法に関する公開ドキュメント"><a href="#（参考情報）文字数カウント方法に関する公開ドキュメント" class="headerlink" title="（参考情報）文字数カウント方法に関する公開ドキュメント"></a>（参考情報）文字数カウント方法に関する公開ドキュメント</h1><p>どのようにAPIが呼び出されるかによって、カウントされる文字数は変わります。<br>例えば、1文字入力の場合でも、その後ろに空白が付与されたままの状態のテキストがAPIに渡された場合、空白も含めた文字数がカウントされます。‘A’ のような状態では、1文字とカウントされますが、後ろに3つ空白を付与した ‘A   ’ のような状態の場合は、4文字とカウントされます。空白の他にも、カウントされる対象がございますので、文字数カウント方法に関する詳細は、下記の公開ドキュメントをご確認ください。  </p><ul><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/translator/character-counts" target="_blank" rel="noopener">Translator Text API の文字数のカウント方法</a></li></ul><hr><p><code>変更履歴</code><br><code>2020/05/28 created by Uehara</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Translator Text API </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Translator Text API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Azure の関連ポータル サイトで一部の Azure サブスクリプションやリソースが表示されない事象の原因と対処策</title>
      <link href="/blog/2020/05/14/cognitive-portal-sub-not-found/"/>
      <url>/blog/2020/05/14/cognitive-portal-sub-not-found/</url>
      
        <content type="html"><![CDATA[<p>Azure の関連ポータル サイトで Azure サブスクリプションやリソースが表示されない原因と対処策について解説します。</p><a id="more"></a><br><hr><p>Azure で提供されているサービスの一部は、Azure ポータル以外に独自のポータル サイトを提供しています。<br>より具体的に Cognitive Services を例に挙げると以下のようなポータル サイトが存在します。</p><ul><li>QnA Maker: <a href="https://www.qnamaker.ai/" target="_blank" rel="noopener">https://www.qnamaker.ai/</a></li><li>Custom Vision: <a href="https://www.customvision.ai/" target="_blank" rel="noopener">https://www.customvision.ai/</a></li><li>Speech Services: <a href="https://speech.microsoft.com/" target="_blank" rel="noopener">https://speech.microsoft.com/</a></li><li>LUIS: <a href="https://www.luis.ai/" target="_blank" rel="noopener">https://www.luis.ai/</a></li></ul><p>これらのポータル サイトは Azure と連携しており、サインインしたユーザーの Azure サブスクリプションやリソースを、ポータル内で表示・操作することができます。</p><p>しかしながら、例えば、以下のように複数の Azure AD ディレクトリ (contoso.onmicrosoft.com と fabrikam.onmicrosoft.com) に関連付けられているユーザー アカウント (user@contoso.onmicrosoft.com) があるとします。この場合、ロールベースのアクセス制御 (RBAC) の設定が適切でも、上記のポータル サイトでサブスクリプションやリソースが表示されないことがあります。</p><p><img src="https://jpaiblog.github.io/images/cognitive-portal-sub-not-found/cognitive-portal-AAD-tenant.png" alt="Cognitive Portal Sign-in"></p><h3 id="■原因"><a href="#■原因" class="headerlink" title="■原因"></a>■原因</h3><p>これらのポータルサイトへ Azure AD の組織アカウントでアカウントサインインする場合、特定の Azure AD ディレクトリに依存しない common エンドポイント (login.microsoftonline.com/<strong>common</strong>/…) が使用されます。この時、サインイン先となるのは、ホーム ディレクトリ  (上記の図では ディレクトリ A の contoso.onmicrosoft.com) となります。通常はこの挙動で問題になることはありません。</p><p>しかし、別のディレクトリにゲスト ユーザーとして招待されることで、複数のディレクトリと関連付けられている場合、ホーム ディレクトリ以外のディレクトリ (上記の図では Bの fabrikam.onmicrosoft.com) に対するサインインは行われないため、そのディレクトリに対するアクセス トークンは取得されません。それにより、ポータルサイト上ではディレクトリ B に紐づいたサブスクリプションやリソースが表示されない事象が発生します。これは Azure AD ディレクトリへのサインインを伴うアクセス権の管理上想定される動作です。</p><h3 id="■対処策"><a href="#■対処策" class="headerlink" title="■対処策"></a>■対処策</h3><p>ディレクトリ B に関連付けられた Azure サブスクリプションに対するアクセス トークンを取得するには、ディレクトリ B へのサインインを明示的に完了する必要があります。</p><h4 id="方法-1-ポータル-サイト内でディレクトリを変更する"><a href="#方法-1-ポータル-サイト内でディレクトリを変更する" class="headerlink" title="方法 1. ポータル サイト内でディレクトリを変更する"></a>方法 1. ポータル サイト内でディレクトリを変更する</h4><p>ポータル サイトによっては、サイト内でディレクトリを切り替える機能が用意されています。この機能を利用してディレクトリ B に切り替えます。</p><p>例. <a href="https://www.customvision.ai/" target="_blank" rel="noopener">Custom Vision ポータル</a>:</p><p><img src="https://jpaiblog.github.io/images/cognitive-portal-sub-not-found/custom-vision-dir-switch.png" alt="Custom Vision portal dir switch"></p><p>これはディレクトリ (テナント) 固有のサインイン エンドポイント (login.microsoftonline.com/<strong>&lt;テナント ID またはテナント名&gt;/</strong>…) を使用してサインインすることで実現されています。</p><p>ご参考: <a href="https://docs.microsoft.com/ja-jp/azure/active-directory/develop/active-directory-v2-protocols#endpoints" target="_blank" rel="noopener">Azure AD のサインイン エンドポイント</a></p><h4 id="方法-2-Azure-ポータルでディレクトリを変更する"><a href="#方法-2-Azure-ポータルでディレクトリを変更する" class="headerlink" title="方法 2. Azure ポータルでディレクトリを変更する"></a>方法 2. Azure ポータルでディレクトリを変更する</h4><p>ポータル サイト内でディレクリを切り替える機能が用意されていない場合は、Azure ポータル (<a href="https://portal.azure.com" target="_blank" rel="noopener">https://portal.azure.com</a>) を使ってディレクトリの切り替えを行います。そして、各サービスのポータルサイト (<a href="https://www.qnamaker.ai/" target="_blank" rel="noopener">QnA Maker</a> など) にアクセスします。</p><p>特にディレクトリ B で多要素認証 (MFA) が強制されているなどサインイン方法に制約がある場合は、こちらの方法をお試しください。</p><p>Azure ポータルでのディレクトリの切り替え方法は次の手順のようになります。</p><ol><li><p>Azure ポータルの画面右上のユーザーアイコンから「ディレクトリの切り替え」を選択します</p><p> <img src="https://jpaiblog.github.io/images/cognitive-portal-sub-not-found/azure-portal-dir-switch-1.png" alt="Azure portal dir switch 1"></p></li><li><p>Azure サブスクリプションが存在するディレクトリを選択してサインインを完了します</p><p> <img src="https://jpaiblog.github.io/images/cognitive-portal-sub-not-found/azure-portal-dir-switch-2.png" alt="Azure portal dir switch 2"></p></li><li><p>Web ブラウザーの別のタブで対象のポータル サイト (例. <a href="https://www.qnamaker.ai/" target="_blank" rel="noopener">QnA Maker</a>) を開きます</p></li></ol><p>もし上記の手順でもポータル サイトで Azure サブスクリプションやリソースが表示されない場合、既定のディレクトリを Azure サブスクリプションが紐づいたディレクトリに変更してから、そのディレクトリに切り替えることで解消するかご確認ください。</p><h3 id="■-補足"><a href="#■-補足" class="headerlink" title="■ 補足"></a>■ 補足</h3><p>ポータル サイト内でディレクトリを切り替える機能が用意されておらず、ホーム ディレクトリでサインインした場合でも、ゲスト ユーザーとして招待されているディレクトリ B に関連付けられた Azure サブスクリプションやリソースがポータル サイト上で表示されることがあります。</p><p>これは他のサイト、例えば Azure ポータルでディレクトリ B にサインインしていた場合、ブラウザーにディレクトリ B の認証情報がキャッシュされ、ディレクトリ B に関連付けられた Azure サブスクリプションに対するアクセス トークンを取得できるためです。</p><p>ディレクトリ B で多要素認証 (MFA) が強制されているなど、サインイン方法に制約がある場合は、キャッシュされたサインイン情報が有効でないため、方法 2 のように Azure ポータルで MFA などの認証を完了する必要があります。  </p><hr><p><code>変更履歴</code><br><code>2020/05/14 created by Chao</code><br><code>2020/05/14 modified by Nakagami</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Cognitive Services </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LUIS </tag>
            
            <tag> QnA Maker </tag>
            
            <tag> Custom Vision </tag>
            
            <tag> Speech Services </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cognitive Serivces で使用する API テスト ページについて</title>
      <link href="/blog/2020/04/30/test-APIs/"/>
      <url>/blog/2020/04/30/test-APIs/</url>
      
        <content type="html"><![CDATA[<p>Cognitive Serivces の API について、テスト実行用の参考サイトを紹介します。</p><a id="more"></a><br><hr><h4 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h4><ul><li><p>Cognitive Serivces の API は複数あります。どのような API があるかは以下サイトを参照ください。<br><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/welcome" target="_blank" rel="noopener">Azure Cognitive Services とは</a>  </p></li><li><p>Azure REST API のリファレンス サイトより、Cognitive Services の REST API を確認できます。いくつかのサービスは、こちらのサイトから REST API の実行が可能です。<br><a href="https://docs.microsoft.com/en-us/rest/api/azure/" target="_blank" rel="noopener">Azure REST API Reference</a><br><a href="https://docs.microsoft.com/en-us/rest/api/cognitiveservices/" target="_blank" rel="noopener">Azure Cognitive Services REST API reference</a><br><a href="https://docs.microsoft.com/en-us/rest/api/cognitiveservices-bingsearch/" target="_blank" rel="noopener">Azure Cognitive Services - Bing Search REST API reference</a>  </p></li><li><p>Cognitive Services 関連の API をまとめたサイトにも REST API を実行可能なページが用意されています。https:// に続くリージョンの指定によっては API が用意されていない場合があるため、代表的な 4 リージョンを紹介します。<br><a href="https://westus.dev.cognitive.microsoft.com/docs/services" target="_blank" rel="noopener">Cognitive Services APIs (westus)</a><br><a href="https://westus2.dev.cognitive.microsoft.com/docs/services" target="_blank" rel="noopener">Cognitive Services APIs (westus2)</a><br><a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services" target="_blank" rel="noopener">Cognitive Services APIs (southcentralus)</a><br><a href="https://westeurope.dev.cognitive.microsoft.com/docs/services" target="_blank" rel="noopener">Cognitive Services APIs (westeurope)</a>  </p></li><li><p>REST API の実行には API キーが必要になります。以下のサイトから API キーを取得できます。こちらにないサービスについては、各サービスのクイック スタート ページ等から利用方法を参照ください。<br><a href="https://azure.microsoft.com/ja-jp/try/cognitive-services/" target="_blank" rel="noopener">Cognitive Services を試す</a>  </p></li></ul><p><br>API のテスト実行可能な直リンクを紹介します。Video Indexer, Bing Speech (廃止), Translator Speech (廃止), Translator Text, Bing Search 系 API は含まれません。</p><hr><h4 id="Computer-Vision"><a href="#Computer-Vision" class="headerlink" title="Computer Vision"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/computer-vision/" target="_blank" rel="noopener">Computer Vision</a></h4><ul><li><a href="https://westus2.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-2-preview-1/operations/5d9869604be85dee480c8750" target="_blank" rel="noopener">v3.2-preview.1</a>  </li><li><a href="https://westus2.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-1-ga/operations/56f91f2e778daf14a499f21b" target="_blank" rel="noopener">v3.1</a>  </li><li><a href="https://westcentralus.dev.cognitive.microsoft.com/docs/services/computer-vision-v3-ga/operations/5d986960601faab4bf452005" target="_blank" rel="noopener">v3.0</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/5cd27ec07268f6c679a3e641/operations/56f91f2e778daf14a499f21b" target="_blank" rel="noopener">v2.1</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa" target="_blank" rel="noopener">v2.0</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fa" target="_blank" rel="noopener">v1.0</a></li></ul><hr><h4 id="Custom-Vision-Service"><a href="#Custom-Vision-Service" class="headerlink" title="Custom Vision Service"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/Custom-Vision-Service/" target="_blank" rel="noopener">Custom Vision Service</a></h4><ul><li><a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/Custom_Vision_Training_3.2/operations/5dddfe4dc8d30b100855c608" target="_blank" rel="noopener">v3.2 Training</a>  </li><li><a href="https://southcentralus.dev.cognitive.microsoft.com/docs/services/Custom_Vision_Prediction_3.0/operations/5c82db60bf6a2b11a8247c15" target="_blank" rel="noopener">v3.0 Prediction</a>  </li></ul><hr><h4 id="Face"><a href="#Face" class="headerlink" title="Face"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/face/" target="_blank" rel="noopener">Face</a></h4><ul><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236" target="_blank" rel="noopener">v1.0</a>  </li></ul><hr><h4 id="Form-Recognizer-Preview"><a href="#Form-Recognizer-Preview" class="headerlink" title="Form Recognizer (Preview)"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/form-recognizer/" target="_blank" rel="noopener">Form Recognizer (Preview)</a></h4><ul><li><a href="https://westus2.dev.cognitive.microsoft.com/docs/services/form-recognizer-api-v2-preview/operations/AnalyzeWithCustomForm" target="_blank" rel="noopener">v2.0 (Preview)</a>  </li></ul><hr><h4 id="Ink-Recognizer-Preview"><a href="#Ink-Recognizer-Preview" class="headerlink" title="Ink Recognizer (Preview)"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/ink-recognizer/" target="_blank" rel="noopener">Ink Recognizer (Preview)</a></h4><ul><li><a href="https://docs.microsoft.com/en-us/rest/api/cognitiveservices/inkrecognizer/inkrecognizer" target="_blank" rel="noopener">v1.0 (Preview)</a>  </li></ul><hr><h4 id="Speech-Service"><a href="#Speech-Service" class="headerlink" title="Speech Service"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/" target="_blank" rel="noopener">Speech Service</a></h4><p>Speech Service はさらに複数のサービス・機能に分かれます。利用可能な REST API の直リンクを以下に列挙します。サービス、機能の一覧は <a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/overview" target="_blank" rel="noopener">こちら</a> をご確認ください。  </p><ul><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speech-service/rest-speech-to-text" target="_blank" rel="noopener">Speech to Text REST API</a>  <ul><li><a href="https://japaneast.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v2-0/operations/GetTranscription/console" target="_blank" rel="noopener">v2.0</a>  </li><li><a href="https://centralus.dev.cognitive.microsoft.com/docs/services/speech-to-text-api-v3-0/operations/CopyModelToSubscription" target="_blank" rel="noopener">v3.0</a>  </li></ul></li><li><a href="https://signature.centralus.cts.speech.microsoft.com/UI/index.html" target="_blank" rel="noopener">Conversation transcription (Preview)</a></li><li><a href="https://docs.microsoft.com/ja-jp/rest/api/speakerrecognition/" target="_blank" rel="noopener">Speaker Recognition</a></li></ul><hr><h4 id="Speaker-Recognition-Preview"><a href="#Speaker-Recognition-Preview" class="headerlink" title="Speaker Recognition (Preview)"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/speaker-recognition/home" target="_blank" rel="noopener">Speaker Recognition (Preview)</a></h4><ul><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/563309b6778daf02acc0a508/operations/5645c3271984551c84ec6797" target="_blank" rel="noopener">v1.0 (Preview)</a>  </li></ul><hr><h4 id="Language-Understanding-LUIS"><a href="#Language-Understanding-LUIS" class="headerlink" title="Language Understanding - LUIS"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/luis/" target="_blank" rel="noopener">Language Understanding - LUIS</a></h4><p>利用可能な REST API の仕様について <a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/luis/developer-reference-resource#rest-specifications" target="_blank" rel="noopener">こちら</a> をご確認ください。  </p><ul><li><a href="https://westeurope.dev.cognitive.microsoft.com/docs/services/luis-programmatic-apis-v3-0-preview/operations/5890b47c39e2bb052c5b9c2f" target="_blank" rel="noopener">v3.0 オーサリング (preview)</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/luis-endpoint-api-v3-0/operations/5cb0a91e54c9db63d589f433" target="_blank" rel="noopener">v3.0 予測</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/5890b47c39e2bb17b84a55ff/operations/5890b47c39e2bb052c5b9c2f" target="_blank" rel="noopener">v2.0 オーサリング</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/5819c76f40a6350ce09de1ac/operations/5819c77140a63516d81aee78" target="_blank" rel="noopener">v2.0 予測</a>  </li></ul><hr><h4 id="QnA-Maker"><a href="#QnA-Maker" class="headerlink" title="QnA Maker"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/qnamaker/" target="_blank" rel="noopener">QnA Maker</a></h4><ul><li><a href="https://docs.microsoft.com/ja-jp/rest/api/cognitiveservices/qnamaker/alterations" target="_blank" rel="noopener">v4.0 Alterations</a>  </li><li><a href="https://docs.microsoft.com/ja-jp/rest/api/cognitiveservices/qnamaker/endpointkeys" target="_blank" rel="noopener">v4.0 Endpoint Keys</a>  </li><li><a href="https://docs.microsoft.com/ja-jp/rest/api/cognitiveservices/qnamaker/endpointsettings" target="_blank" rel="noopener">v4.0 Endpoint Settings</a>  </li><li><a href="https://docs.microsoft.com/ja-jp/rest/api/cognitiveservices/qnamaker/knowledgebase" target="_blank" rel="noopener">v4.0 Knowledgebase</a>  </li><li><a href="https://docs.microsoft.com/ja-jp/rest/api/cognitiveservices/qnamaker/operations" target="_blank" rel="noopener">v4.0 Operations</a>  </li><li><a href="https://docs.microsoft.com/ja-jp/rest/api/cognitiveservices/qnamakerruntime/runtime" target="_blank" rel="noopener">v4.0 Runtime</a>  </li></ul><hr><h4 id="Text-Analytics"><a href="#Text-Analytics" class="headerlink" title="Text Analytics"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/text-analytics/" target="_blank" rel="noopener">Text Analytics</a></h4><ul><li><a href="https://centralus.dev.cognitive.microsoft.com/docs/services/TextAnalytics-v3-1-Preview-2/operations/Languages" target="_blank" rel="noopener">v3.1-preview.2</a>  </li><li><a href="https://centralus.dev.cognitive.microsoft.com/docs/services/TextAnalytics-v3-1-Preview-1/operations/Languages" target="_blank" rel="noopener">v3.1-preview.1</a>  </li><li><a href="https://centralus.dev.cognitive.microsoft.com/docs/services/TextAnalytics-v3-0/operations/Languages" target="_blank" rel="noopener">v3.0</a>  </li><li><a href="https://centralus.dev.cognitive.microsoft.com/docs/services/TextAnalytics-v2-1/operations/56f30ceeeda5650db055a3c7" target="_blank" rel="noopener">v2.1</a>  </li></ul><hr><h4 id="Anomaly-Detector-Preview"><a href="#Anomaly-Detector-Preview" class="headerlink" title="Anomaly Detector (Preview)"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/anomaly-detector/" target="_blank" rel="noopener">Anomaly Detector (Preview)</a></h4><ul><li><a href="https://westus2.dev.cognitive.microsoft.com/docs/services/AnomalyDetector/operations/post-timeseries-last-detect" target="_blank" rel="noopener">v1.0 (Preview)</a>  </li></ul><hr><h4 id="Content-Moderator"><a href="#Content-Moderator" class="headerlink" title="Content Moderator"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/content-moderator/" target="_blank" rel="noopener">Content Moderator</a></h4><ul><li><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/content-moderator/api-reference" target="_blank" rel="noopener">Content Moderator API リファレンス</a><ul><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/57cf753a3f9b070c105bd2c1/operations/57cf753a3f9b070868a1f66c" target="_blank" rel="noopener">Content Moderator (Image, Text)</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/57cf755e3f9b070c105bd2c2/operations/57cf755e3f9b070868a1f675" target="_blank" rel="noopener">List Management</a>  </li><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/580519463f9b070e5c591178/operations/5813b4103f9b0711b43c5c67" target="_blank" rel="noopener">Review (Job, Review, Workflow)</a></li></ul></li></ul><hr><h4 id="Metrics-Advisor-Preview"><a href="#Metrics-Advisor-Preview" class="headerlink" title="Metrics Advisor (Preview)"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/metrics-advisor/" target="_blank" rel="noopener">Metrics Advisor (Preview)</a></h4><ul><li><a href="https://westus2.dev.cognitive.microsoft.com/docs/services/MetricsAdvisor/operations/createDataFeed" target="_blank" rel="noopener">v1.0 (Preview)</a></li></ul><hr><h4 id="Personalizer"><a href="#Personalizer" class="headerlink" title="Personalizer"></a><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/personalizer/" target="_blank" rel="noopener">Personalizer</a></h4><ul><li><a href="https://westus2.dev.cognitive.microsoft.com/docs/services/personalizer-api/operations/Rank" target="_blank" rel="noopener">v1.0</a>  </li></ul><hr><p><code>変更履歴</code><br><code>2020/04/30 created by Mochizuki</code><br><code>2020/05/01 modified by Mochizuki</code><br><code>2020/10/19 modified by Mochizuki</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Cognitive Services </category>
          
      </categories>
      
      
        <tags>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ポータルにサインインできない事象について (AADSTS650051)</title>
      <link href="/blog/2020/03/07/error-AADSTS650051/"/>
      <url>/blog/2020/03/07/error-AADSTS650051/</url>
      
        <content type="html"><![CDATA[<p>エラー コード AADSTS650051 を含むメッセージが出力し、製品ポータル (<a href="http://www.luis.ai" target="_blank" rel="noopener">www.luis.ai</a> や <a href="http://www.customvision.ai" target="_blank" rel="noopener">www.customvision.ai</a> など) へのサインインが失敗する場合の対処方法を紹介します。</p><a id="more"></a><br><hr><p>下記エラーメッセージは (ドメイン名) の DNS 名に紐づく Azure AD のテナントが、管理者不在のバイラル (非管理) テナントと呼ばれる状態 (unmanaged state) であり、それが原因でポータルへサインインできないことを意味します。  </p><blockquote><p>ErrorDescription’: ‘AADSTS650051: Using application ‘&lt;ポータル FQDN&gt;’ is currently not supported for your organization &lt;ドメイン名&gt; because it is in an unmanaged state. An administrator needs to claim ownership of the company by DNS validation of &lt;ドメイン名&gt; before the application &lt;ポータル FQDN&gt; can be provisioned.`</p></blockquote><p>類似のサービスに関する記事とはなりますが、詳細と対処方法は以下をご参照ください。  </p><ul><li><a href="https://docs.microsoft.com/ja-jp/archive/blogs/jpcognitiveblog/cannot-signin-custom-vision-service-portal" target="_blank" rel="noopener">非管理テナントのアカウントで Custom Vision Service のポータルにサインインできない場合の対処方法</a></li></ul><p>この問題は、当該テナントに紐づく (ドメイン名) のドメインの所有確認を行うことで解消されるため、以下のドキュメントの “3. 「管理者になる」メニューを実行します。” まで実施ください。  </p><ul><li><a href="https://docs.microsoft.com/ja-jp/archive/blogs/exchangeteamjp/domain-registered-by-self-service-sign-up" target="_blank" rel="noopener">セルフサービス サインアップで登録されたドメインの対処方法</a></li></ul><p>なお、この問題を解消するだけであれば、手順 4 以降の作業は必要ありませんが、手順 3 を実施する段階で DNS の設定変更が必要となります。Azure AD テナントやドメインの管理者にて確認ください。<br><br></p><p>関連する公開情報:</p><ul><li><a href="https://docs.microsoft.com/ja-jp/azure/active-directory/b2b/troubleshoot#you-receive-an-aadsts65005-error-when-you-try-to-log-in-to-an-azure-resource" target="_blank" rel="noopener">Azure リソースにログインしようとすると “AADSTS65005” エラーを受け取ります</a></li><li><a href="https://docs.microsoft.com/ja-jp/azure/active-directory/users-groups-roles/domains-admin-takeover" target="_blank" rel="noopener">Azure Active Directory の非管理対象ディレクトリを管理者として引き継ぐ</a></li></ul><hr><p><code>変更履歴</code><br><code>2020/03/07 created by Mochizuki</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Cognitive Services </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AADSTS650051 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>QNA Maker の管理サービス (Cognitive Services リソース) のリージョンについて</title>
      <link href="/blog/2020/03/03/QNA-management-service/"/>
      <url>/blog/2020/03/03/QNA-management-service/</url>
      
        <content type="html"><![CDATA[<p>QNA Maker の管理サービス (Cognitive Services リソース) についてご紹介します。</p><a id="more"></a><br><hr><p>QnA Maker サービスの全体構成は下記ドキュメントの図を参照ください。  </p><ul><li><p><a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/qnamaker/concepts/azure-resources" target="_blank" rel="noopener">QnA Maker 用の Azure リソース</a></p><p> <img src="https://jpaiblog.github.io/images/QNA-management-service/key-management.png" alt="QNA Maker">  </p></li></ul><p>Cognitive Services としてのリソースは、図中の右上の QnA Maker Subscription に相当します。例えば、ポータルを操作して KB を編集した場合、米国西部リージョンにおいてホストされている API 群が呼び出されます (5. Manage KB in portal or via APIs)。この API 群を別リージョンに移行することができないため、<a href="https://docs.microsoft.com/ja-jp/azure/cognitive-services/qnamaker/concepts/azure-resources#management-service-region" target="_blank" rel="noopener">こちらのサイト</a> の記載の通り、Cognitive Services リソースは米国西部リージョン固定になります。  </p><p>米国西部リージョンにある API のバックエンドから、Web Apps 上でホストされた QnA Maker ランタイムに対してアクセスし、Q&amp;A の追加や削除といった操作が行われます。なお、実際の KB のコンテンツ (Q&amp;A、メタデータ等) は Azure Search に保存されており、ユーザーのチャットログは Application Insights に保存されているため、顧客データは米国西部リージョンには保存されません。  </p><p>※ 管理サービスで使用する API の詳細は以下サイトを参照ください。  </p><ul><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/5a93fcf85b4ccd136866eb37/operations/5ac266295b4ccd1554da75ff" target="_blank" rel="noopener">QnA Maker V4.0</a>  </li></ul><p>KB を公開した後の、ボット等のアプリケーションからの問い合わせ (4. User QnA endpoint in Bot) は GenerateAnswer API が使用されます。これは QnA Maker ランタイム (Web Apps) に対して直接アクセスするため、米国西部リージョンを経由することはありません。</p><p>※ GenerateAnswer API の詳細は以下サイトをご参照ください。  </p><ul><li><a href="https://westus.dev.cognitive.microsoft.com/docs/services/5a93fcf85b4ccd136866eb37/operations/5ac266295b4ccd1554da75ff" target="_blank" rel="noopener">GenerateAnswer API およびメタデータを使って回答を取得する</a>  </li></ul><hr><p><code>変更履歴</code><br><code>2020/03/03 created by Mochizuki</code>  </p>]]></content>
      
      
      <categories>
          
          <category> QNA Maker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 管理サービス </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>過去ブログについて</title>
      <link href="/blog/2020/01/12/past-blog/"/>
      <url>/blog/2020/01/12/past-blog/</url>
      
        <content type="html"><![CDATA[<p>過去のブログ情報を紹介します。</p><a id="more"></a><br><hr><h2 id="Cognitive-Services"><a href="#Cognitive-Services" class="headerlink" title="Cognitive Services"></a>Cognitive Services</h2><ul><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/255a225d-24e5-4e21-ad28-7fab33088131/translator-text-api-?forum=cognitivesupportteamja" target="_blank" rel="noopener">Translator Text API の翻訳文字数の確認方法</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/fee57b8d-8d08-4036-9d2e-ad4f48812624/open-api-testing-console?forum=cognitivesupportteamja" target="_blank" rel="noopener">Open API Testing Console</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/9555e55e-2af0-4130-948a-74ee3f6d349e/http-401-access-denied-invalid-subscription-key-?forum=cognitivesupportteamja" target="_blank" rel="noopener">HTTP 401 Access Denied (invalid subscription key) のエラーが発生した場合の切り分け方法</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/9586428d-1ad8-4838-bac8-b37da05d9d47/cognitive-services-?forum=cognitivesupportteamja" target="_blank" rel="noopener">Cognitive Services の料金について</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/1fc6d90a-f335-4a51-bbb4-7c168bf8358e/luis-wwwluisai-?forum=cognitivesupportteamja" target="_blank" rel="noopener">LUIS ポータル (www.luis.ai) にサインインできない場合の対処方法</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/bcf0ea4b-04f2-4b81-9963-34d85b3594ef/qna-maker-api-v4-azure-search-?forum=cognitivesupportteamja" target="_blank" rel="noopener">QnA Maker API V4 (一般公開版) の Azure Search に関するよくあるご質問</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/d4235f66-2c6d-4ad8-87ba-ec859e5bb33f/-custom-vision-service-?forum=cognitivesupportteamja" target="_blank" rel="noopener">非管理テナントのアカウントで Custom Vision Service のポータルにサインインできない場合の対処方法</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/d1b413b3-d0a7-4fb9-9938-01a52cb5f914/qna-maker-api-v4-?forum=cognitivesupportteamja" target="_blank" rel="noopener">QnA Maker API V4 (一般公開版) のよくあるご質問</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/e9917891-e99e-481f-a32a-34f853fdd22b/bing-speech-api-api-10-15-?forum=cognitivesupportteamja" target="_blank" rel="noopener">Bing Speech API の新規 API キー作成は 10 月 15 日で終了しました</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/5b3b97c3-532e-489c-b0cb-5546a2988427/cognitive-services-?forum=cognitivesupportteamja" target="_blank" rel="noopener">Cognitive Services の技術サポートのお問い合わせ方法</a></li><li><a href="https://social.msdn.microsoft.com/Forums/ja-JP/ecab7e31-dddb-48bf-8a8f-7a9f347ae1b5/cognitive-services-tls-12-?forum=cognitivesupportteamja" target="_blank" rel="noopener">Cognitive Services への接続には TLS 1.2 をご利用ください</a></li></ul><hr><p><code>変更履歴</code><br><code>2020/01/12 created by Mochizuki</code>  </p>]]></content>
      
      
      <categories>
          
          <category> Cognitive Services </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 過去ブログ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>jpaiblog について</title>
      <link href="/blog/2020/01/01/about-jpaiblog/"/>
      <url>/blog/2020/01/01/about-jpaiblog/</url>
      
        <content type="html"><![CDATA[<p>日本マイクロソフトの Cognitive Serivce に関するサポート情報のブログです。</p><h3 id="公開日"><a href="#公開日" class="headerlink" title="公開日"></a>公開日</h3><p>2020 年 1 月 1 日より公開いたしました。</p><h3 id="活動について"><a href="#活動について" class="headerlink" title="活動について"></a>活動について</h3><p>製品のサポート メンバーによって運用されております。仕様に関する情報やトラブル シューティングの手順、実装におけるワンポイント アドバイスを公開いたします。</p><h3 id="留意事項"><a href="#留意事項" class="headerlink" title="留意事項"></a>留意事項</h3><p>サイトのコンテンツや情報において、可能な限り正確な情報を掲載し、更新するよう努めております。しかしながら、状況の変化や情報が古くなることにより、必ずしもお客様環境に適用できない情報となる場合がございます。恐れ入りますが、予めご留意くださいますようお願い申し上げます。</p>]]></content>
      
      
      <categories>
          
          <category> Cognitive Services </category>
          
      </categories>
      
      
        <tags>
            
            <tag> はじめに </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
